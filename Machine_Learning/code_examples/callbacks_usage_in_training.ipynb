{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Callbacks usage in training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foobar167/articles/blob/master/Machine_Learning/code_examples/callbacks_usage_in_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lGbzH8SrcE8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "360ff8fc-279d-476c-d187-616023f4f85d"
      },
      "cell_type": "code",
      "source": [
        "# Install the newest nightly build of TensorFlow\n",
        "!pip install tf-nightly-2.0-preview\n",
        "#!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/9f/4bb6f12c8960fa24b576daeaf02bc03b725b0673d990f1e4b8293d9bb196/tf_nightly_2.0_preview-2.0.0.dev20190424-cp36-cp36m-manylinux1_x86_64.whl (86.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 86.8MB 433kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.33.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Collecting wrapt>=1.11.1 (from tf-nightly-2.0-preview)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.16.3)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/64/55c16bf21186f214c0aaa06f7798815dddb6ef25ddd1477615e852292069/tb_nightly-1.14.0a20190424-py3-none-any.whl (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.9)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/ef/c050a0dd0b1855b30a3568264888fcaa7a87c42e4dfda6036657a5bff029/tensorflow_estimator_2.0_preview-1.14.0.dev2019042300-py2.py3-none-any.whl (421kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 20.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview) (40.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (3.1)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built wrapt\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: wrapt, tb-nightly, tensorflow-estimator-2.0-preview, google-pasta, tf-nightly-2.0-preview\n",
            "  Found existing installation: wrapt 1.10.11\n",
            "    Uninstalling wrapt-1.10.11:\n",
            "      Successfully uninstalled wrapt-1.10.11\n",
            "Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190424 tensorflow-estimator-2.0-preview-1.14.0.dev2019042300 tf-nightly-2.0-preview-2.0.0.dev20190424 wrapt-1.11.1\n",
            "2.0.0-dev20190424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGkd6Ga-whot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37b5d887-2ab2-43a0-d4f3-3f758392bcd8"
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rru1mXMYcInx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1395
        },
        "outputId": "3d31e0dd-86f3-413a-ed92-770a1e8736b0"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Just train to 90% accuracy and stop.\n",
        "class myCallback1(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') > 0.9):\n",
        "            print('\\nReached 90% accuracy, so cancelling training!')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Not useful for wavelike training.\n",
        "class myCallback2(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.patience = 10\n",
        "        self.curr_patience = 0\n",
        "        self.curr_evaluate = [float('inf')]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        evaluate = model.evaluate(x_test, y_test)\n",
        "        print(evaluate[-1], self.curr_patience, self.curr_evaluate[-1])\n",
        "        if evaluate[-1] > self.curr_evaluate[-1]:\n",
        "            self.curr_patience += 1\n",
        "        self.curr_evaluate = evaluate\n",
        "        if self.curr_patience >= self.patience:\n",
        "            print('\\nModel has started to overfit, so cancelling training')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Use EarlyStopping callback to stop training before overfitting\n",
        "myCallback3 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "callback = myCallback2()  # select callback\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist  # get link on the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # load data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # normalize the model\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=100, callbacks=[callback])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 1s 55us/sample - loss: 0.4003 - accuracy: 0.8540\n",
            "0.854 0 inf\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4751 - accuracy: 0.8299\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3681 - accuracy: 0.8694\n",
            "0.8694 0 0.854\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3589 - accuracy: 0.8673\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 0s 49us/sample - loss: 0.3480 - accuracy: 0.8783\n",
            "0.8783 1 0.8694\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3238 - accuracy: 0.8794\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3769 - accuracy: 0.8595\n",
            "0.8595 2 0.8783\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2984 - accuracy: 0.8896\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3502 - accuracy: 0.8724\n",
            "0.8724 2 0.8595\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2808 - accuracy: 0.8953\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 1s 52us/sample - loss: 0.3285 - accuracy: 0.8824\n",
            "0.8824 3 0.8724\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2640 - accuracy: 0.9006\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3366 - accuracy: 0.8820\n",
            "0.882 4 0.8824\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.2529 - accuracy: 0.9048\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3428 - accuracy: 0.8755\n",
            "0.8755 4 0.882\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2420 - accuracy: 0.9103\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3310 - accuracy: 0.8901\n",
            "0.8901 4 0.8755\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2323 - accuracy: 0.9122\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3341 - accuracy: 0.8830\n",
            "0.883 5 0.8901\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2219 - accuracy: 0.9168\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3273 - accuracy: 0.8893\n",
            "0.8893 5 0.883\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2119 - accuracy: 0.9212\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3479 - accuracy: 0.8804\n",
            "0.8804 6 0.8893\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2066 - accuracy: 0.9236\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3357 - accuracy: 0.8868\n",
            "0.8868 6 0.8804\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1971 - accuracy: 0.9247\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.3421 - accuracy: 0.8887\n",
            "0.8887 7 0.8868\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1899 - accuracy: 0.9296\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3419 - accuracy: 0.8836\n",
            "0.8836 8 0.8887\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1844 - accuracy: 0.9317\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3502 - accuracy: 0.8922\n",
            "0.8922 8 0.8836\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1821 - accuracy: 0.9317\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3660 - accuracy: 0.8852\n",
            "0.8852 9 0.8922\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1730 - accuracy: 0.9354\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 1s 53us/sample - loss: 0.3749 - accuracy: 0.8854\n",
            "0.8854 9 0.8852\n",
            "\n",
            "Model has started to overfit, so cancelling training\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1684 - accuracy: 0.9373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b1e06b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "laHBjCXbcIwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f4400b0c-6729-463a-8160-2f153c2b2d54"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model. Old evaluation.\n",
        "print(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 49us/sample - loss: 0.9551 - accuracy: 0.8911\n",
            "[0.9551087798453868, 0.8911]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2JF7S1NvcI5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b56dc61a-46c8-49a3-f707-682181c57b64"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model. New evaluation.\n",
        "print(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 51us/sample - loss: 0.3749 - accuracy: 0.8854\n",
            "[0.37486174614429474, 0.8854]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9W4NjYgCDab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
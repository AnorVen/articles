<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <title>Введение в машинное обучение и искусственные нейронные сети</title>
    <link rel="stylesheet" type="text/css" href="data/styles.css"/>
</head>

<body>
<h1>Введение в машинное обучение и искусственные нейронные сети</h1>

<div class="left">
    Автор: Дмитрий Павленко<br/>
    Author: Dzmitry Paulenka<br/>
    E-mail: <a href="mailto:foobar167@gmail.com">foobar167@gmail.com</a><br/>
    <a href="https://github.com/foobar167/articles/blob/master/Machine_Learning/Vvedeniye_v_mashinnoye_obucheniye_i_iskusstvennyye_neyronnyye_seti.pdf" target="_blank">
        PDF копия</a><br/>
    16 декабря 2018, версия 1.0<br/>
</div>

<br/><b>Оглавление</b><br/>
<a href="#ref1"><b>Глава1. Введение в машинное обучение</b></a><br/>
<div class="left">
    <a href="#ref1.1">Что такое машинное обучение</a><br/>
    <a href="#ref1.2">Типы обучения</a><br/>
    <a href="#ref1.3">Способы обучения</a><br/>
    <a href="#ref1.4">Решаемые задачи</a><br/>
    <a href="#ref1.5">Сферы применения</a><br/>
    <a href="#ref1.6">Краткая история</a><br/>
    <a href="#ref1.7">Модели машинного обучения</a><br/>
    <a href="#ref1.8">Список литературы</a><br/>
</div>
<a href="#ref2"><b>Глава 2. Введение в искусственные нейронные сети</b></a><br/>
<div class="left">
    <a href="#ref2.1">Принципы работы искусственных нейронных сетей</a><br/>
    <div class="left">
        <a href="#ref2.1.1">Обзор основных архитектур ИНС</a><br/>
        <a href="#ref2.1.2">Функции активации нейрона</a><br/>
        <a href="#ref2.1.3">Свёрточные ИНС</a><br/>
        <a href="#ref2.1.4">Метод обратного распространения ошибки (backpropagation)</a><br/>
        <a href="#ref2.1.5">Переобучение и недообучение</a><br/>
    </div>
    <a href="#ref2.2">Рекомендации по созданию обучающей выборки</a><br/>
    <div class="left">
        <a href="#ref2.2.1">Важность правильной подготовки данных</a><br/>
        <a href="#ref2.2.2">Аугментация данных (data augmentation)</a><br/>
        <a href="#ref2.2.3">Отбор признаков (feature selection)</a><br/>
        <a href="#ref2.2.4">Извлечение признаков (feature extraction)</a><br/>
        <a href="#ref2.2.5">Проектирование признаков (feature engineering)</a><br/>
        <a href="#ref2.2.6">Преобразования признаков (feature transformations)</a><br/>
    </div>
    <a href="#ref2.3">Обучение модели</a><br/>
    <div class="left">
        <a href="#ref2.3.1">Разбиение данных для обучения и оценки</a><br/>
        <a href="#ref2.3.2">Процесс обучения</a><br/>
        <a href="#ref2.3.3">Оценка качества обучения</a><br/>
    </div>
    <a href="#ref2.4">Процесс решения задачи в машинном обучении</a><br/>
    <a href="#ref2.5">Список литературы</a><br/>
</div>

<h2><a name="ref1">Глава1. Введение в машинное обучение</a></h2>

<div class="citation">«По сути, все модели ошибочны, но некоторые из них полезны», –<br/>
    Джордж Бокс, статистик [1.1]<br/>
</div>

<h3><a name="ref1.1">Что такое машинное обучение</a></h3>

<p>
    <i>Машинное обучение</i> (machine learning, ML) – это раздел информатики, который занимается
    разработкой и анализом алгоритмов, позволяющих компьютерам меняться под воздействием внешних
    факторов (обучаться). Алгоритмы обучения (learning algorithms) делают предсказания или принимают
    решения не на основе строго статических программных команд, а на основе обучающей выборки
    (т.е. обучающих данных), с помощью которой происходит настройка параметров модели. Для процесса
    настройки (fitting) модели по выборке данных применяются различные разделы математики:
    математическая статистика, методы оптимизации, численные методы, теория вероятностей, линейная
    алгебра, математический анализ, дискретная математика, теория графов, различные техники работы
    с цифровыми данными и др. Результатом работы алгоритма обучения является функция, которая
    аппроксимирует (восстанавливает) неизвестную зависимость в обрабатываемых данных.<br/>
</p>

<p>
    Машинное обучение является не только математической, но и прикладной, инженерной дисциплиной.
    Практически ни одно исследование в области машинного обучения не обходится без последующего
    тестирования на реальных данных для проверки практической работоспособности разрабатываемого метода.<br/>
</p>

<p>
    Когда говорят о машинном обучении, то часто имеют ввиду вновь ставшие популярными искусственные
    нейронные сети (ИНС) и глубокое обучение, которые являются моделями машинного обучения
    (рисунок 1.1), т.е. частными случаями методов распознавания образов, дискриминантного анализа,
    методов кластеризации и т. п.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.1-Vlozhennost-kategoriy-mashinnogo-obucheniya.png"
         alt="Вложенность категорий" height="160" /><br/>
    <div class="picture">Рис. 1.1 – Вложенность категорий</div>
</div>

<h3><a name="ref1.2">Типы обучения</a></h3>

<p>
    Есть три типа методов машинного обучения: дедуктивное, индуктивное и трансдуктивное.<br/>
</p>

<p>
    <i>Дедуктивное</i> обучение или обучение «сверху-вниз», от общего к частному предполагает
    формализацию знаний экспертов и их перенос в компьютер в виде базы знаний. Дедуктивное обучение
    принято относить к области экспертных систем. Имеются знания, сформулированные экспертом и
    каким-либо образом формализованные через уравнения, теоремы, зависимости и т.д. Программа,
    экспертная система, выводит из этих правил конкретные факты и новые правила.<br/>
</p>

<p>
    <i>Индуктивное</i> обучение или обучение «снизу-вверх», от частного к общему, обучение на примерах,
    обучение по прецедентам, основано на выявлении закономерностей в эмпирических данных,
    т.е. данных полученных путём наблюдения или эксперимента. Индуктивное обучение компьютеров принято
    относить к машинному обучению. Многие методы индуктивного обучения разрабатывались как альтернатива
    классическим статистическим подходам и тесно связаны с извлечением информации (information extraction)
    и интеллектуальным анализом данных (data mining). На основе эмпирических данных программа строит
    общее правило. Эмпирические данные могут быть получены самой программой в предыдущие сеансы её
    работы или просто предъявлены ей.<br/>
</p>

<p>
    <i>Трансдуктивное</i> обучение [1.2] или обучение от частного к частному, позволяет на основе
    эмпирических данных без выявления общих закономерностей и формализации знаний сделать выводы
    о других эмпирических данных. Понятие трансдукции было предложено
    <a href="https://en.wikipedia.org/wiki/Vladimir_Vapnik" target="_blank">Владимиром Вапником</a>
    в 1990 году: «При решении интересующей проблемы не решайте более общую проблему как промежуточный шаг.
    Постарайтесь получить ответ, который вам действительно нужен, но не более общий». Например, если
    не учитывать объекты без метки (рисунок 1.2), тогда невозможно правильно сегментировать множество,
    потому что слишком мало размеченных объектов.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.2-Primer-transduktivnogo-obucheniya.png"
         alt="Пример трансдуктивного обучения" height="240" /><br/>
    <div class="picture">Рис. 1.2 – Пример трансдуктивного обучения</div>
</div>

<p>
    При решении задачи методом индукции, когда ищется общий ответ для всех возможных случаев,
    неразмеченные объекты не учитываются, их как бы нет для решающего задачу, потому что с точки
    зрения индуктивного обучения могут быть и другие неразмеченные объекты кроме имеющихся.
    Учёт присутствующих неразмеченных данных может кардинально изменить качество решения, но если
    появятся новые неразмеченные данные, то их появление может полностью изменить ответ.
    Трансдуктивное обучение применяется в некоторых методах машинного обучения с частичным
    привлечением учителя (semi-supervised learning). Взаимосвязь между тремя типами обучения
    можно увидеть на рисунке 1.3.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.3-Tri-tipa-obucheniya.png"
         alt="Три типа обучения" height="240" /><br/>
    <div class="picture">Рис. 1.3 – Три типа обучения</div>
</div>

<p>
    Будем считать задачу обучения экзаменом, размеченные объекты – как решённые учителем примеры,
    а неразмеченные объекты – как предоставленные учителем нерешённые примеры. С точки зрения
    дедуктивного обучения у вас уже есть формула, показанная вам учителем, с помощью которой вы
    можете решить все нерешённые задачи на экзамене, поэтому нет смысла решать предоставленные
    учителем нерешённые примеры. С точки зрения индуктивного обучения нерешённые примеры являются
    подобными тем, которые будут на экзамене. С точки зрения трансдуктивного обучения данные
    учителем нерешённые примеры и есть экзамен, т.е. эти же примеры будут на экзамене.<br/>
</p>

<h3><a name="ref1.3">Способы обучения</a></h3>

<p>
    Методы машинного обучения обычно разделяются на две обширные категории, в зависимости от наличия
    обучающего «сигнала» или «обратной связи» для алгоритма обучения: <i>обучение с учителем</i>
    (supervised learning) и <i>обучение без учителя</i> (unsupervised learning).<br/>
</p>

<p>
    При обучении с учителем система обучается на примерах с заранее известными правильными ответами.
    На основе этих входных примеров и известных правильных ответов требуется восстановить
    зависимость между множеством примеров и множеством ответов, т.е. построить алгоритм, который
    будет выдавать достаточно точный ответ для любого примера. Совокупность примеров
    (входных объектов) и соответствующих им правильных ответов называется <i>обучающей выборкой</i>.
    Пусть обучающая выборка описывается парой значений <span class="formula">〈x, y〉</span>,
    где <span class="formula">x=〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>〉</span> – это данные
    (многомерный вектор признаков), <span class="formula">y</span> – это целевое значение
    (метка или правильный ответ). Надо найти функцию <span class="formula">&fnof;(x)=y</span>.<br/>
</p>

<p>
    Обучение без учителя, самообучение, происходит на примерах без заранее известных правильных ответов.
    Система сама находит внутренние взаимосвязи, зависимости, закономерности, существующие между
    объектами без вмешательства внешнего учителя, экспериментатора, человека. Пусть каждый объект описан
    вектором признаков <span class="formula">x=〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>〉</span>.
    Надо найти механизм, который описывает структуру этих данных, которая заранее не известна.<br/>
</p>

<p>
    Комбинированные виды обучения применяют различные сочетания обоих типов обучения
    в одной программе. Например, <i>обучение с частичным привлечением учителя</i>,
    <i>обучение с подкреплением</i> и некоторые другие.<br/>
</p>

<p>
    При обучении с подкреплением учителем является сама окружающая среда, модель среды или
    неявный учитель, например, одновременная активность нескольких нейронов
    в искусственной нейронной сети.<br/>
</p>

<p>
    Не всегда удаётся найти хорошую обучающую выборку. Часто данные размечены не полностью, т.е.
    не для всех данных есть правильный ответ (метка). Разметка данных для машинного обучения является
    однообразным и долгим трудом. Обычно имеется небольшое количество размеченных данных и большое
    количество неразмеченных данных. В этом случае применяется обучение с частичным привлечением учителя.
    Его ещё называют полуавтоматическим обучением (semi-supervised learning). Многие исследователи
    машинного обучения обнаружили, что неразмеченные данные, при использовании в сочетании с небольшим
    количеством размеченных данных, могут значительно улучшить точность обучения.
    Обучение с частичным привлечением учителя является частным случаем трансдуктивного обучения.<br/>
</p>

<h3><a name="ref1.4">Решаемые задачи</a></h3>

<p>
    Методы машинного обучения разделяются по типам решаемых задач: классификация, кластеризация,
    регрессия, прогнозирование, идентификация, восстановление плотности распределения вероятности
    по набору данных, понижение размерности, одноклассовая классификация и выявление новизны,
    построение ранговых зависимостей и т.д. Продолжают возникать новые типы задач и даже целые новые
    дисциплины машинного обучения, например, добыча данных (data mining).<br/>
</p>

<p>
    <i>Классификация</i> – разделение множества объектов или ситуаций на классы с помощью обучения
    с учителем. Классифицировать объект – значит, указать номер, имя или метку класса, к которому
    относится данный объект. Иногда требуется указать вероятность отношения объекта к классу. Например,
    по обучающей выборке фотографий котов и собак научиться различать изображения котов и собак.<br/>
</p>

<p>
    <i>Кластеризация</i> (сегментация) – разделение множества объектов или ситуаций на кластеры
    с помощью обучения без учителя. Кластеризация (обучение без учителя) отличается от классификации
    (обучения с учителем) тем, что перечень групп четко не задан и определяется в процессе работы
    алгоритма, т.е. нет заранее определённых «правильных» ответов. Иногда указывается общее
    количество кластеров, но часто алгоритм сам выбирает оптимальное количество кластеров.
    Похожесть или близость объектов в кластере определяется через расстояние в многомерном
    пространстве признаков. Для этого нужно определить само пространство признаков (какие свойства
    измеряются) и метрику близости (как считается расстояние). Результаты кластеризации применяются
    при нахождении новых, ранее неизвестных знаний и зависимостей в данных (добыча данных или
    data mining). Например, задача нахождения целевой аудитории определённого товара путём анализа
    потребительских корзин покупателей с учётом пола, возраста, социального статуса,
    семейного положения и т.д.<br/>
</p>

<p>
    <i>Регрессия</i> – нахождение зависимости выходной переменной от одной или нескольких
    независимых входных переменных с помощью обучения с учителем. В отличие он задач классификации,
    которые разделяют объекты на дискретное количество классов, задачи регрессии находят зависимости
    между непрерывными величинами. Например, нахождение зависимости между количеством съеденной пищи
    и весом тела.<br/>
</p>

<p>
    <i>Прогнозирование</i> – это предсказание во времени. Прогнозирование похоже либо на регрессию,
    либо на классификацию в зависимости от данных задачи (непрерывные или дискретные данные),
    но в отличие от регрессии и классификации всегда направлено в будущее. В прогнозировании данные
    упорядочиваются по времени, которое является явным и ключевым параметром, а найденная зависимость
    экстраполируется в будущее. В прогнозировании применяются модели временных рядов.<br/>
</p>

<p>
    <i>Идентификация</i>. Идентификация и классификация многими ошибочно понимаются как синонимы.
    Задача идентификации исторически возникла из задачи классификации, когда вместо определения класса
    объекта потребовалось уметь определять, обладает объект требуемым свойством или нет.
    Особенностью задачи идентификации является то, что все объекты принадлежат одному классу,
    и не существует возможности разделить класс на подклассы, т.е. сделать состоятельную выборку
    из класса, которая не будет обладать требуемым свойством. Если требуется определить человека по
    фотографии его лица, причём множество запомненных в базе людей постоянно меняется и появляются люди,
    которых не было в обучающем множестве, то это задача идентификации, которая не сводится к задаче
    классификации. В случае определения объекта по фотографии функция идентификации
    <span class="formula">&fnof;(x<sub>1</sub>,x<sub>2</sub>)</span> принимает в качестве аргументов
    два вектора признаков фотографий, а на выходе равна либо 1 в случае фотографий одного и того же
    объекта либо 0 в случае фотографий разных объектов одного и того же класса.<br/>
</p>

<p>
    <i>Восстановление плотности распределения вероятности по набору данных</i> (kernel density estimate).
    Данная задача является центральной проблемой математической статистики. Математическая статистика
    решает обратные задачи: по результату эксперимента определяет свойства закона распределения.
    Исчерпывающей характеристикой закона распределения является плотность распределения вероятностей.
    Например, известен возраст людей, берущих кредит в банке, требуется найти плотность распределения
    вероятности возрастов заёмщиков.<br/>
</p>

<p>
    <i>Понижение размерности</i> данных и их визуализация. Является частным случаем кластеризации.
    Каждый объект может быть представлен в виде многомерного вектора признаков
    <span class="formula">〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>〉</span>,
    нужно получить более компактное признаковое описание объекта
    <span class="formula">〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>k</sub>〉</span>, где
    <span class="formula">k < n</span>. Понижение размерности может помочь другим методам путём
    устранения избыточных данных. Используется при разведочном анализе и для устранения
    «проклятия размерности», когда данные быстро становятся разреженными при увеличении размерности
    пространства признаков. Например, дан список документов на человеческом языке,
    требуется найти документы с похожими темами.<br/>
</p>

<p>
    <i>Одноклассовая классификация и выявление новизны</i>. Или задача поиска аномалий, выбросов,
    которые не относятся ни к одному кластеру. Нахождение объектов, которые отличаются по своим
    свойствам от объектов обучающей выборки. Является задачей обучения без учителя. Например,
    обнаружение инородных предметов (кости, камни, кусочки упаковки) в продуктах питания при их
    сканировании рентгеновским сканером при неразрушающем контроле качества продукции, обнаружение
    подозрительных банковских операций, обнаружение хакерской атаки, медицинская диагностика и т.д.<br/>
</p>

<p>
    Построение ранговых зависимостей. <i>Ранжирование</i> – это процедура упорядочения объектов
    по степени выраженности какого-либо качества в порядке убывания этого качества.
    Задачами ранжирования являются: сортировка веб-страниц согласно заданному поисковому запросу,
    персонализация новостной ленты, рекомендации товаров (видео, музыки), адресная реклама.<br/>
</p>

<p>
    <i>Добыча данных</i> (data mining) или интеллектуальный анализ данных [1.3] – совокупность
    методов обнаружения в данных ранее неизвестных, нетривиальных, практически полезных и доступных
    интерпретации знаний, необходимых для принятия решений в различных сферах человеческой
    деятельности. В данный момент добыча данных отделяется от машинного обучения в отдельную
    дисциплину. Интеллектуальный анализ данных и машинное обучение имеют различные цели:
    машинное обучение прогнозирует на основе известных свойств, полученных от обучающей выборки,
    а интеллектуальный анализ данных фокусируется на добыче новых ранее неизвестных зависимостей
    в данных. Однако обе дисциплины используют одинаковые методы.<br/>
</p>

<p>
    Различные типы задач схематически представлены на рисунке 1.4.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.4-Skhematicheskoye-predstavleniye-tipov-zadach-mashinnogo-obucheniya.png"
         alt="Схематическое представление типов задач" height="770" /><br/>
    <div class="picture">Рис. 1.4 – Схематическое представление типов задач:<br/>
        1) классификация; 2) кластеризация; 3) регрессия; 4) прогнозирование; 5) идентификация;<br/>
        6) восстановление плотности распределения вероятности по набору данных;<br/>
        7) понижение размерности; 8) одноклассовая классификация и выявление новизны;<br/>
        9) построение ранговых зависимостей; 10) добыча данных.<br/>
    </div>
</div>

<h3><a name="ref1.5">Сферы применения</a></h3>

<p>
    Целью машинного обучения является частичная или полная автоматизация
    человеческой деятельности в самых разных областях.<br/>
</p>

<p>
    Распознавание речи – преобразование голосового сигнала в цифровую информацию, например,
    текст или запрос для поискового сервера. Обратной задачей является синтез речи.<br/>
</p>

<p>
    Распознавание жестов – преобразование жестов в цифровую информацию: текст,
    клавиатурные команды. Распознавание эмоций и мимики.<br/>
</p>

<p>
    Распознавание рукописных текстов – преобразование рукописного текста в цифровую информацию.<br/>
</p>

<p>
    Распознавание образов и, в частности, компьютерное зрение – классификация и идентификация
    объектов по характерным конечным наборам свойств и признаков.<br/>
</p>

<p>
    Техническая диагностика – определение технического состояния объектов.<br/>
</p>

<p>
    Медицинская диагностика – процесс установления диагноза, т.е. заключения о сущности болезни
    и состоянии пациента. Анализ данных с сенсоров.<br/>
</p>

<p>
    Прогнозирование временных рядов – предсказание будущих значений временного ряда
    по настоящим и прошлым значениям.<br/>
</p>

<p>
    Биоинформатика – междисциплинарная наука, использующая методы прикладной математики,
    статистики и информатики в биохимии, биофизике, экологии, геномике и в других областях.<br/>
</p>

<p>
    Обнаружение мошенничества – автоматическое обнаружение противоправных действий.<br/>
</p>

<p>
    Обнаружение спама – обнаружение массовой рассылки корреспонденции рекламного или иного характера
    лицам, не выражавшим желания её получать.<br/>
</p>

<p>
    Категоризация документов – отнесении документа к одной из нескольких категорий
    на основании содержания документа.<br/>
</p>

<p>
    Биржевой технический анализ – прогнозирование вероятного изменения цен на основе закономерностей
    изменений цен в прошлом в аналогичных обстоятельствах.<br/>
</p>

<p>
    Финансовый надзор – это деятельность уполномоченных органов, направленная на исполнение требований
    законодательства органами государственной власти, органами местного самоуправления,
    их должностными лицами, юридическими лицами и гражданами с целью выявления, пресечения и
    предупреждения правонарушений, обеспечения законности и финансовой дисциплины.<br/>
</p>

<p>
    Кредитный скоринг – система оценки кредитоспособности (кредитных рисков) лиц,
    основанная на численных статистических методах.<br/>
</p>

<p>
    Прогнозирование ухода клиентов – прогнозирование потери клиентов, выраженное в отсутствии покупок
    или платежей в течение определенного периода времени для компаний с подписной и транзакционной
    моделью бизнеса (банки, операторы связи, SaaS-сервисы), подразумевающих регулярные платежи
    в сторону компании.<br/>
</p>

<p>
    Хемоинформатика (химическая информатика, молекулярная информатика) – применение методов
    информатики для решения задач химии и синтеза новых соединений.<br/>
</p>

<p>
    Обучение ранжированию в информационном поиске – увеличение качества поиска, создание
    рекомендательных систем, оценка качества найденной информации.<br/>
</p>

<p>
    Навигация и контроль действий – помощь водителям транспортных средств, а также беспилотные
    транспортные средства, автоматический контроль транспортных потоков.<br/>
</p>

<p>
    Домашняя автоматизация – система домашних устройств, способных выполнять действия и решать
    определенные повседневные задачи без участия человека.<br/>
</p>

<p>
    Машинное обучение бурно развивается, поэтому постоянно появляются новые
    не перечисленные здесь сферы применения.<br/>
</p>

<h3><a name="ref1.6">Краткая история</a></h3>

<p>
    Термин «машинное обучение» в 1959 году ввёл исследователь в области компьютерных игр
    Артур Самуэль в своей работе «Некоторые исследования в области Машинного Обучения
    с использованием игры в шашки» [1.4] и определил его как «процесс, в результате которого
    машина (компьютер) способна показывать поведение, которое в неё не было явно заложено
    (запрограммировано)». Игру в шашки, изобретенную Самуэлем в 1952 году, принято считать
    первой программой, способной самообучаться. Самуэль выбрал шашки, потому что правила игры
    относительно просты, но имеют развитую стратегию.<br/>
</p>

<p>
    Эффективность машинного обучения в решении задач была продемонстрирована достаточно давно:
    еще в 1936 году знаменитый английский статистик Рональд Фишер сумел научить компьютер
    определять вид ириса по ширине цветка и чашелистика.<br/>
</p>

<p>
    В тридцатые годы 20 века Карел Чапек изобрел термин «робот», в сороковые годы Айзек Азимов
    сформулировал законы робототехники, но первым, кто перевёл проблему «интеллектуальных машин»
    из научной фантастики в разряд прикладных проблем был математик Алан Тьюринг. В 1950 году
    в своей работе «Вычислительные машины и разум» [1.5] он рассмотрел вопрос
    «Могут ли машины думать?», но так как термины «машины» и «думать» не могут быть определены
    однозначно, Тьюринг предложил заменить вопрос на другой, тесно связанный с первым, но выраженный
    не такими двусмысленными понятиями: <i>может ли машина совершать действия, неотличимые от
    обдуманных действий</i>. С помощью такой постановки вопроса можно избежать сложных философских
    проблем по определению терминов «думать», «мышление» и сосредоточить внимание
    на решении практических задач.<br/>
</p>

<p>
    Заменив философский вопрос на прикладной, Тьюринг предложил для проверки возможностей компьютерной
    программы свой знаменитый <i>Тест Тьюринга</i>. Стандартная интерпретация этого теста звучит
    следующим образом: «Человек взаимодействует с одним компьютером и одним человеком.
    На основании ответов на вопросы он должен определить, с кем он разговаривает: с человеком
    или компьютерной программой. Задача компьютерной программы – ввести человека в заблуждение,
    заставив сделать неверный выбор». Однако Тьюринг говорит не об одурачивании людей,
    а о воспроизведении когнитивных способностей человека [1.6]. Хотя бы внешне.<br/>
</p>

<p>Тест Тьюринга имеет недостатки:</p>
<ul>
    <li>чрезмерный антропоморфизм (рисунок 1.5);</li>
    <li>непрактичность – самолёты не машут крыльями, как птицы, чтобы летать, а машины не обязаны
        имитировать поведение людей, чтобы решать прикладные задачи;</li>
    <li>возможность имитации «мышления» по неким механическим правилам, например, как в мысленном
        эксперименте «Китайская комната» Джона Сёрля (John Searle, 1980).</li>
</ul>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.5-Povedeniye-cheloveka-i-razumnoye-povedeniye.png"
         alt="Поведение человека и разумное поведение" height="220" /><br/>
    <div class="picture">Рис. 1.5 – Поведение человека и разумное поведение</div>
</div>

<p>
    Несмотря на обоснованную критику, тест Тьюринга задаёт правильное направление мысли, а именно:
    не важно, думает машина или нет, потому что нет однозначного определения слов «думать» или «интеллект»,
    главное, что машина <i>может</i> справляться с поставленными перед ней сложными задачами, например,
    имитировать поведение человека.<br/>
</p>

<p>
    Современный интерес к машинному обучению возрос после того, как искусственные нейронные сети
    вновь стали популярными. <i>Искусственная нейронная сеть</i> (ИНС) – это математическая модель,
    а также её программное или аппаратное воплощение, построенная по принципу организации и
    функционирования биологических нейронных сетей, т.е. сетей нервных клеток живого организма.
    Необязательно, чтобы строение ИНС и мозга совпадали. В ИНС воплощены идеи <i>коннекционизма</i>,
    т.е. моделирования мыслительных или поведенческих явлений в сетях
    из связанных между собой простых элементов.<br/>
</p>

<p>
    Первой попыткой построить ИНС по принципу функционирования мозга были нейронные сети
    Уоррена Мак-Каллока и Уолтера Питтса, описанные в статье 1943 года «Логическое исчисление идей,
    относящихся к нервной активности» [1.7, 1.8]. По примеру классических философов Греции они
    попытались математически смоделировать работу мозга. Это была яркая идея, учитывая то,
    что электрическая природа сигналов нейронов будет продемонстрирована только спустя семь лет
    в конце 1950-х годов. Математическая модель сети Мак-Каллока и Питтса из искусственных нейронов
    (рисунок 1.6) теоретически могла выполнять числовые или логические операции любой сложности.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.6-Skhema-iskusstvennogo-neyrona.png"
         alt="Схема искусственного нейрона" height="360" /><br/>
    <div class="picture">Рис. 1.6 – Схема искусственного нейрона:<br/>
        1) нейроны, выходные сигналы которых поступают на вход данному;<br/>
        2) ω<sub>i</sub> – веса входных сигналов; 3) сумматор входных сигналов;<br/>
        4) вычислитель передаточной (активационной) функции;<br/>
        5) нейроны, на входы которых подаётся выходной сигнал данного<br/>
    </div>
</div>

<p>
    На вход искусственного нейрона поступают импульсы от произвольного числа других нейронов сети.
    Связи, по которым выходные сигналы одних нейронов поступают на входы других, часто называют
    <i>синапсами</i> по аналогии со связями между биологическими нейронами.
    Каждая связь характеризуется своим весом. Связи с положительным весом называются возбуждающими,
    а с отрицательным – тормозящими. Нейрон имеет один выход, часто называемый <i>аксоном</i>
    по аналогии с биологическим прототипом. С единственного выхода нейрона сигнал может поступать
    на произвольное число входов других нейронов. Если на выходе нейрона есть ненулевой сигнал
    (положительный или отрицательный), то говорят, что нейрон активен или возбуждён.<br/>
</p>

<p>
    В сумматоре поступающие импульсы на вход нейрона умножаются на веса входов и слаживаются:<br/>
</p>

<table class="formula">
    <tr>
        <td class="formula"></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Formula1.1-Indutsirovannoye-lokalnoye-pole-neyrona.png"
                 alt="Индуцированное локальное поле нейрона или взвешенная сумма" class="formula" /></td>
        <td class="formula">(1.1)</td>
    </tr>
</table>

<p class="formula">
    где <span class="formula">n</span> – количество входящих синапсов;
    <span class="formula">ω<sub>i</sub></span> – веса входов (положительные возбуждающие
    или отрицательные тормозящие); <span class="formula">x<sub>i</sub></span> – сигналы на входах;
    <span class="formula">C</span> – константа для формирования порога чувствительности нейрона,
    которая называется сдвиг (bias). Функция <span class="formula">x</span> называется индуцированным
    локальным полем нейрона или <i>взвешенной суммой</i>. Возможные значения сигналов на входах
    нейрона <span class="formula">x<sub>i</sub></span> считают заданными в интервале
    <span class="formula">[0,1]</span>. Сигналы на входах, в зависимости от архитектуры сети,
    могут быть либо дискретными (только 0 или только 1), либо аналоговыми
    (непрерывными в интервале от 0 до 1 включительно).<br/>
</p>

<p>
    Затем к индуцированному локальному полю нейрона <span class="formula">x</span> (см. формулу 1.1)
    применяется функция, называемая передаточной функцией <span class="formula">&fnof;(x)</span>
    или функцией активации, функцией срабатывания, которая определяет зависимость сигнала на выходе
    нейрона от взвешенной суммы сигналов на его входах. Использование различных передаточных функций
    позволяет вносить нелинейность в работу нейрона и в целом нейронной сети. Без этой нелинейности
    нейронная сеть вырождается в задачу линейной алгебры, т.е. в обычное перемножение матриц и векторов.<br/>
</p>

<p>
    Существует множество различных передаточных функций. Самой известной передаточной функцией
    является <i>функция Хевисайда</i> (рисунок 1.7), которая представляет собой перепад (ступеньку)
    и записывается формулой:<br/>
</p>

<table class="formula">
    <tr>
        <td class="formula"></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Formula1.2-Funktsiya-Khevisayda-ili-stupenka.png"
                 alt="Функция Хевисайда или «ступенька»" class="formula" /></td>
        <td class="formula">(1.2)</td>
    </tr>
</table>

</body>
</html>

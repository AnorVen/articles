<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <title>Введение в машинное обучение и искусственные нейронные сети</title>
    <link rel="stylesheet" type="text/css" href="data/styles.css"/>
</head>

<body>
<h1>Введение в машинное обучение и искусственные нейронные сети</h1>

<div class="left">
    Автор: Дмитрий Павленко<br/>
    Author: Dzmitry Paulenka<br/>
    E-mail: <a href="mailto:foobar167@gmail.com">foobar167@gmail.com</a><br/>
    <a href="https://github.com/foobar167/articles/blob/master/Machine_Learning/Vvedeniye_v_mashinnoye_obucheniye_i_iskusstvennyye_neyronnyye_seti.pdf" target="_blank">
        Скачать PDF копию</a><br/>
    16 декабря 2018, версия 1.0<br/>
</div>

<br/><b>Оглавление</b><br/>
<a href="#ref1"><b>Глава1. Введение в машинное обучение</b></a><br/>
<div class="left">
    <a href="#ref1.1">Что такое машинное обучение</a><br/>
    <a href="#ref1.2">Типы обучения</a><br/>
    <a href="#ref1.3">Способы обучения</a><br/>
    <a href="#ref1.4">Решаемые задачи</a><br/>
    <a href="#ref1.5">Сферы применения</a><br/>
    <a href="#ref1.6">Краткая история</a><br/>
    <a href="#ref1.7">Модели машинного обучения</a><br/>
    <a href="#ref1.8">Список литературы</a><br/>
</div>
<a href="#ref2"><b>Глава 2. Введение в искусственные нейронные сети</b></a><br/>
<div class="left">
    <a href="#ref2.1">Принципы работы искусственных нейронных сетей</a><br/>
    <div class="left">
        <a href="#ref2.1.1">Обзор основных архитектур ИНС</a><br/>
        <a href="#ref2.1.2">Функции активации нейрона</a><br/>
        <a href="#ref2.1.3">Свёрточные ИНС</a><br/>
        <a href="#ref2.1.4">Метод обратного распространения ошибки (backpropagation)</a><br/>
        <a href="#ref2.1.5">Переобучение и недообучение</a><br/>
    </div>
    <a href="#ref2.2">Рекомендации по созданию обучающей выборки</a><br/>
    <div class="left">
        <a href="#ref2.2.1">Важность правильной подготовки данных</a><br/>
        <a href="#ref2.2.2">Аугментация данных (data augmentation)</a><br/>
        <a href="#ref2.2.3">Отбор признаков (feature selection)</a><br/>
        <a href="#ref2.2.4">Извлечение признаков (feature extraction)</a><br/>
        <a href="#ref2.2.5">Проектирование признаков (feature engineering)</a><br/>
        <a href="#ref2.2.6">Преобразования признаков (feature transformations)</a><br/>
    </div>
    <a href="#ref2.3">Обучение модели</a><br/>
    <div class="left">
        <a href="#ref2.3.1">Разбиение данных для обучения и оценки</a><br/>
        <a href="#ref2.3.2">Процесс обучения</a><br/>
        <a href="#ref2.3.3">Оценка качества обучения</a><br/>
    </div>
    <a href="#ref2.4">Процесс решения задачи в машинном обучении</a><br/>
    <a href="#ref2.5">Список литературы</a><br/>
</div>

<h2><a name="ref1">Глава1. Введение в машинное обучение</a></h2>

<div class="citation">
    «По сути, все модели ошибочны, но некоторые из них полезны», –<br/>
    Джордж Бокс, статистик [1.1]<br/>
</div>

<h3><a name="ref1.1">Что такое машинное обучение</a></h3>

<p>
    <i>Машинное обучение</i> (machine learning, ML) – это раздел информатики, который занимается
    разработкой и анализом алгоритмов, позволяющих компьютерам меняться под воздействием внешних
    факторов (обучаться). Алгоритмы обучения (learning algorithms) делают предсказания или принимают
    решения не на основе строго статических программных команд, а на основе обучающей выборки
    (т.е. обучающих данных), с помощью которой происходит настройка параметров модели. Для процесса
    настройки (fitting) модели по выборке данных применяются различные разделы математики:
    математическая статистика, методы оптимизации, численные методы, теория вероятностей, линейная
    алгебра, математический анализ, дискретная математика, теория графов, различные техники работы
    с цифровыми данными и др. Результатом работы алгоритма обучения является функция, которая
    аппроксимирует (восстанавливает) неизвестную зависимость в обрабатываемых данных.<br/>
</p>

<p>
    Машинное обучение является не только математической, но и прикладной, инженерной дисциплиной.
    Практически ни одно исследование в области машинного обучения не обходится без последующего
    тестирования на реальных данных для проверки практической работоспособности разрабатываемого метода.<br/>
</p>

<p>
    Когда говорят о машинном обучении, то часто имеют ввиду вновь ставшие популярными искусственные
    нейронные сети (ИНС) и глубокое обучение, которые являются моделями машинного обучения
    (рисунок 1.1), т.е. частными случаями методов распознавания образов, дискриминантного анализа,
    методов кластеризации и т. п.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.1-Vlozhennost-kategoriy-mashinnogo-obucheniya.png"
         alt="Вложенность категорий машинного обучения"
         title="Вложенность категорий машинного обучения"
         height="160" /><br/>
    <div class="picture">Рис. 1.1 – Вложенность категорий</div>
</div>

<h3><a name="ref1.2">Типы обучения</a></h3>

<p>
    Есть три типа методов машинного обучения: дедуктивное, индуктивное и трансдуктивное.<br/>
</p>

<p>
    <i>Дедуктивное</i> обучение или обучение «сверху-вниз», от общего к частному предполагает
    формализацию знаний экспертов и их перенос в компьютер в виде базы знаний. Дедуктивное обучение
    принято относить к области экспертных систем. Имеются знания, сформулированные экспертом и
    каким-либо образом формализованные через уравнения, теоремы, зависимости и т.д. Программа,
    экспертная система, выводит из этих правил конкретные факты и новые правила.<br/>
</p>

<p>
    <i>Индуктивное</i> обучение или обучение «снизу-вверх», от частного к общему, обучение на примерах,
    обучение по прецедентам, основано на выявлении закономерностей в эмпирических данных,
    т.е. данных полученных путём наблюдения или эксперимента. Индуктивное обучение компьютеров принято
    относить к машинному обучению. Многие методы индуктивного обучения разрабатывались как альтернатива
    классическим статистическим подходам и тесно связаны с извлечением информации (information extraction)
    и интеллектуальным анализом данных (data mining). На основе эмпирических данных программа строит
    общее правило. Эмпирические данные могут быть получены самой программой в предыдущие сеансы её
    работы или просто предъявлены ей.<br/>
</p>

<p>
    <i>Трансдуктивное</i> обучение [1.2] или обучение от частного к частному, позволяет на основе
    эмпирических данных без выявления общих закономерностей и формализации знаний сделать выводы
    о других эмпирических данных. Понятие трансдукции было предложено
    <a href="https://en.wikipedia.org/wiki/Vladimir_Vapnik" target="_blank">Владимиром Вапником</a>
    в 1990 году: «При решении интересующей проблемы не решайте более общую проблему как промежуточный шаг.
    Постарайтесь получить ответ, который вам действительно нужен, но не более общий». Например, если
    не учитывать объекты без метки (рисунок 1.2), тогда невозможно правильно сегментировать множество,
    потому что слишком мало размеченных объектов.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.2-Primer-transduktivnogo-obucheniya.png"
         alt="Пример трансдуктивного обучения"
         title="Пример трансдуктивного обучения"
         height="240" /><br/>
    <div class="picture">Рис. 1.2 – Пример трансдуктивного обучения</div>
</div>

<p>
    При решении задачи методом индукции, когда ищется общий ответ для всех возможных случаев,
    неразмеченные объекты не учитываются, их как бы нет для решающего задачу, потому что с точки
    зрения индуктивного обучения могут быть и другие неразмеченные объекты кроме имеющихся.
    Учёт присутствующих неразмеченных данных может кардинально изменить качество решения, но если
    появятся новые неразмеченные данные, то их появление может полностью изменить ответ.
    Трансдуктивное обучение применяется в некоторых методах машинного обучения с частичным
    привлечением учителя (semi-supervised learning). Взаимосвязь между тремя типами обучения
    можно увидеть на рисунке 1.3.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.3-Tri-tipa-obucheniya.png"
         alt="Три типа обучения"
         title="Три типа обучения"
         height="240" /><br/>
    <div class="picture">Рис. 1.3 – Три типа обучения</div>
</div>

<p>
    Будем считать задачу обучения экзаменом, размеченные объекты – как решённые учителем примеры,
    а неразмеченные объекты – как предоставленные учителем нерешённые примеры. С точки зрения
    дедуктивного обучения у вас уже есть формула, показанная вам учителем, с помощью которой вы
    можете решить все нерешённые задачи на экзамене, поэтому нет смысла решать предоставленные
    учителем нерешённые примеры. С точки зрения индуктивного обучения нерешённые примеры являются
    подобными тем, которые будут на экзамене. С точки зрения трансдуктивного обучения данные
    учителем нерешённые примеры и есть экзамен, т.е. эти же примеры будут на экзамене.<br/>
</p>

<h3><a name="ref1.3">Способы обучения</a></h3>

<p>
    Методы машинного обучения обычно разделяются на две обширные категории, в зависимости от наличия
    обучающего «сигнала» или «обратной связи» для алгоритма обучения: <i>обучение с учителем</i>
    (supervised learning) и <i>обучение без учителя</i> (unsupervised learning).<br/>
</p>

<p>
    При обучении с учителем система обучается на примерах с заранее известными правильными ответами.
    На основе этих входных примеров и известных правильных ответов требуется восстановить
    зависимость между множеством примеров и множеством ответов, т.е. построить алгоритм, который
    будет выдавать достаточно точный ответ для любого примера. Совокупность примеров
    (входных объектов) и соответствующих им правильных ответов называется <i>обучающей выборкой</i>.
    Пусть обучающая выборка описывается парой значений <span class="formula">〈x, y〉</span>,
    где <span class="formula">x=〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>〉</span> – это данные
    (многомерный вектор признаков), <span class="formula">y</span> – это целевое значение
    (метка или правильный ответ). Надо найти функцию <span class="formula">&fnof;(x)=y</span>.<br/>
</p>

<p>
    Обучение без учителя, самообучение, происходит на примерах без заранее известных правильных ответов.
    Система сама находит внутренние взаимосвязи, зависимости, закономерности, существующие между
    объектами без вмешательства внешнего учителя, экспериментатора, человека. Пусть каждый объект описан
    вектором признаков <span class="formula">x=〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>〉</span>.
    Надо найти механизм, который описывает структуру этих данных, которая заранее не известна.<br/>
</p>

<p>
    Комбинированные виды обучения применяют различные сочетания обоих типов обучения
    в одной программе. Например, <i>обучение с частичным привлечением учителя</i>,
    <i>обучение с подкреплением</i> и некоторые другие.<br/>
</p>

<p>
    При обучении с подкреплением учителем является сама окружающая среда, модель среды или
    неявный учитель, например, одновременная активность нескольких нейронов
    в искусственной нейронной сети.<br/>
</p>

<p>
    Не всегда удаётся найти хорошую обучающую выборку. Часто данные размечены не полностью, т.е.
    не для всех данных есть правильный ответ (метка). Разметка данных для машинного обучения является
    однообразным и долгим трудом. Обычно имеется небольшое количество размеченных данных и большое
    количество неразмеченных данных. В этом случае применяется обучение с частичным привлечением учителя.
    Его ещё называют полуавтоматическим обучением (semi-supervised learning). Многие исследователи
    машинного обучения обнаружили, что неразмеченные данные, при использовании в сочетании с небольшим
    количеством размеченных данных, могут значительно улучшить точность обучения.
    Обучение с частичным привлечением учителя является частным случаем трансдуктивного обучения.<br/>
</p>

<h3><a name="ref1.4">Решаемые задачи</a></h3>

<p>
    Методы машинного обучения разделяются по типам решаемых задач: классификация, кластеризация,
    регрессия, прогнозирование, идентификация, восстановление плотности распределения вероятности
    по набору данных, понижение размерности, одноклассовая классификация и выявление новизны,
    построение ранговых зависимостей и т.д. Продолжают возникать новые типы задач и даже целые новые
    дисциплины машинного обучения, например, добыча данных (data mining).<br/>
</p>

<p>
    <i>Классификация</i> – разделение множества объектов или ситуаций на классы с помощью обучения
    с учителем. Классифицировать объект – значит, указать номер, имя или метку класса, к которому
    относится данный объект. Иногда требуется указать вероятность отношения объекта к классу. Например,
    по обучающей выборке фотографий котов и собак научиться различать изображения котов и собак.<br/>
</p>

<p>
    <i>Кластеризация</i> (сегментация) – разделение множества объектов или ситуаций на кластеры
    с помощью обучения без учителя. Кластеризация (обучение без учителя) отличается от классификации
    (обучения с учителем) тем, что перечень групп четко не задан и определяется в процессе работы
    алгоритма, т.е. нет заранее определённых «правильных» ответов. Иногда указывается общее
    количество кластеров, но часто алгоритм сам выбирает оптимальное количество кластеров.
    Похожесть или близость объектов в кластере определяется через расстояние в многомерном
    пространстве признаков. Для этого нужно определить само пространство признаков (какие свойства
    измеряются) и метрику близости (как считается расстояние). Результаты кластеризации применяются
    при нахождении новых, ранее неизвестных знаний и зависимостей в данных (добыча данных или
    data mining). Например, задача нахождения целевой аудитории определённого товара путём анализа
    потребительских корзин покупателей с учётом пола, возраста, социального статуса,
    семейного положения и т.д.<br/>
</p>

<p>
    <i>Регрессия</i> – нахождение зависимости выходной переменной от одной или нескольких
    независимых входных переменных с помощью обучения с учителем. В отличие он задач классификации,
    которые разделяют объекты на дискретное количество классов, задачи регрессии находят зависимости
    между непрерывными величинами. Например, нахождение зависимости между количеством съеденной пищи
    и весом тела.<br/>
</p>

<p>
    <i>Прогнозирование</i> – это предсказание во времени. Прогнозирование похоже либо на регрессию,
    либо на классификацию в зависимости от данных задачи (непрерывные или дискретные данные),
    но в отличие от регрессии и классификации всегда направлено в будущее. В прогнозировании данные
    упорядочиваются по времени, которое является явным и ключевым параметром, а найденная зависимость
    экстраполируется в будущее. В прогнозировании применяются модели временных рядов.<br/>
</p>

<p>
    <i>Идентификация</i>. Идентификация и классификация многими ошибочно понимаются как синонимы.
    Задача идентификации исторически возникла из задачи классификации, когда вместо определения класса
    объекта потребовалось уметь определять, обладает объект требуемым свойством или нет.
    Особенностью задачи идентификации является то, что все объекты принадлежат одному классу,
    и не существует возможности разделить класс на подклассы, т.е. сделать состоятельную выборку
    из класса, которая не будет обладать требуемым свойством. Если требуется определить человека по
    фотографии его лица, причём множество запомненных в базе людей постоянно меняется и появляются люди,
    которых не было в обучающем множестве, то это задача идентификации, которая не сводится к задаче
    классификации. В случае определения объекта по фотографии функция идентификации
    <span class="formula">&fnof;(x<sub>1</sub>,x<sub>2</sub>)</span> принимает в качестве аргументов
    два вектора признаков фотографий, а на выходе равна либо 1 в случае фотографий одного и того же
    объекта либо 0 в случае фотографий разных объектов одного и того же класса.<br/>
</p>

<p>
    <i>Восстановление плотности распределения вероятности по набору данных</i> (kernel density estimate).
    Данная задача является центральной проблемой математической статистики. Математическая статистика
    решает обратные задачи: по результату эксперимента определяет свойства закона распределения.
    Исчерпывающей характеристикой закона распределения является плотность распределения вероятностей.
    Например, известен возраст людей, берущих кредит в банке, требуется найти плотность распределения
    вероятности возрастов заёмщиков.<br/>
</p>

<p>
    <i>Понижение размерности</i> данных и их визуализация. Является частным случаем кластеризации.
    Каждый объект может быть представлен в виде многомерного вектора признаков
    <span class="formula">〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>n</sub>〉</span>,
    нужно получить более компактное признаковое описание объекта
    <span class="formula">〈x<sub>1</sub>,x<sub>2</sub>,…,x<sub>k</sub>〉</span>, где
    <span class="formula">k < n</span>. Понижение размерности может помочь другим методам путём
    устранения избыточных данных. Используется при разведочном анализе и для устранения
    «проклятия размерности», когда данные быстро становятся разреженными при увеличении размерности
    пространства признаков. Например, дан список документов на человеческом языке,
    требуется найти документы с похожими темами.<br/>
</p>

<p>
    <i>Одноклассовая классификация и выявление новизны</i>. Или задача поиска аномалий, выбросов,
    которые не относятся ни к одному кластеру. Нахождение объектов, которые отличаются по своим
    свойствам от объектов обучающей выборки. Является задачей обучения без учителя. Например,
    обнаружение инородных предметов (кости, камни, кусочки упаковки) в продуктах питания при их
    сканировании рентгеновским сканером при неразрушающем контроле качества продукции, обнаружение
    подозрительных банковских операций, обнаружение хакерской атаки, медицинская диагностика и т.д.<br/>
</p>

<p>
    Построение ранговых зависимостей. <i>Ранжирование</i> – это процедура упорядочения объектов
    по степени выраженности какого-либо качества в порядке убывания этого качества.
    Задачами ранжирования являются: сортировка веб-страниц согласно заданному поисковому запросу,
    персонализация новостной ленты, рекомендации товаров (видео, музыки), адресная реклама.<br/>
</p>

<p>
    <i>Добыча данных</i> (data mining) или интеллектуальный анализ данных [1.3] – совокупность
    методов обнаружения в данных ранее неизвестных, нетривиальных, практически полезных и доступных
    интерпретации знаний, необходимых для принятия решений в различных сферах человеческой
    деятельности. В данный момент добыча данных отделяется от машинного обучения в отдельную
    дисциплину. Интеллектуальный анализ данных и машинное обучение имеют различные цели:
    машинное обучение прогнозирует на основе известных свойств, полученных от обучающей выборки,
    а интеллектуальный анализ данных фокусируется на добыче новых ранее неизвестных зависимостей
    в данных. Однако обе дисциплины используют одинаковые методы.<br/>
</p>

<p>
    Различные типы задач схематически представлены на рисунке 1.4.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.4-Skhematicheskoye-predstavleniye-tipov-zadach-mashinnogo-obucheniya.png"
         alt="Схематическое представление типов задач машинного обучения"
         title="Схематическое представление типов задач машинного обучения"
         height="770" /><br/>
    <div class="picture">
        Рис. 1.4 – Схематическое представление типов задач:<br/>
        1) классификация; 2) кластеризация; 3) регрессия; 4) прогнозирование; 5) идентификация;<br/>
        6) восстановление плотности распределения вероятности по набору данных;<br/>
        7) понижение размерности; 8) одноклассовая классификация и выявление новизны;<br/>
        9) построение ранговых зависимостей; 10) добыча данных.<br/>
    </div>
</div>

<h3><a name="ref1.5">Сферы применения</a></h3>

<p>
    Целью машинного обучения является частичная или полная автоматизация
    человеческой деятельности в самых разных областях.<br/>
</p>

<p>
    Распознавание речи – преобразование голосового сигнала в цифровую информацию, например,
    текст или запрос для поискового сервера. Обратной задачей является синтез речи.<br/>
</p>

<p>
    Распознавание жестов – преобразование жестов в цифровую информацию: текст,
    клавиатурные команды. Распознавание эмоций и мимики.<br/>
</p>

<p>
    Распознавание рукописных текстов – преобразование рукописного текста в цифровую информацию.<br/>
</p>

<p>
    Распознавание образов и, в частности, компьютерное зрение – классификация и идентификация
    объектов по характерным конечным наборам свойств и признаков.<br/>
</p>

<p>
    Техническая диагностика – определение технического состояния объектов.<br/>
</p>

<p>
    Медицинская диагностика – процесс установления диагноза, т.е. заключения о сущности болезни
    и состоянии пациента. Анализ данных с сенсоров.<br/>
</p>

<p>
    Прогнозирование временных рядов – предсказание будущих значений временного ряда
    по настоящим и прошлым значениям.<br/>
</p>

<p>
    Биоинформатика – междисциплинарная наука, использующая методы прикладной математики,
    статистики и информатики в биохимии, биофизике, экологии, геномике и в других областях.<br/>
</p>

<p>
    Обнаружение мошенничества – автоматическое обнаружение противоправных действий.<br/>
</p>

<p>
    Обнаружение спама – обнаружение массовой рассылки корреспонденции рекламного или иного характера
    лицам, не выражавшим желания её получать.<br/>
</p>

<p>
    Категоризация документов – отнесении документа к одной из нескольких категорий
    на основании содержания документа.<br/>
</p>

<p>
    Биржевой технический анализ – прогнозирование вероятного изменения цен на основе закономерностей
    изменений цен в прошлом в аналогичных обстоятельствах.<br/>
</p>

<p>
    Финансовый надзор – это деятельность уполномоченных органов, направленная на исполнение требований
    законодательства органами государственной власти, органами местного самоуправления,
    их должностными лицами, юридическими лицами и гражданами с целью выявления, пресечения и
    предупреждения правонарушений, обеспечения законности и финансовой дисциплины.<br/>
</p>

<p>
    Кредитный скоринг – система оценки кредитоспособности (кредитных рисков) лиц,
    основанная на численных статистических методах.<br/>
</p>

<p>
    Прогнозирование ухода клиентов – прогнозирование потери клиентов, выраженное в отсутствии покупок
    или платежей в течение определенного периода времени для компаний с подписной и транзакционной
    моделью бизнеса (банки, операторы связи, SaaS-сервисы), подразумевающих регулярные платежи
    в сторону компании.<br/>
</p>

<p>
    Хемоинформатика (химическая информатика, молекулярная информатика) – применение методов
    информатики для решения задач химии и синтеза новых соединений.<br/>
</p>

<p>
    Обучение ранжированию в информационном поиске – увеличение качества поиска, создание
    рекомендательных систем, оценка качества найденной информации.<br/>
</p>

<p>
    Навигация и контроль действий – помощь водителям транспортных средств, а также беспилотные
    транспортные средства, автоматический контроль транспортных потоков.<br/>
</p>

<p>
    Домашняя автоматизация – система домашних устройств, способных выполнять действия и решать
    определенные повседневные задачи без участия человека.<br/>
</p>

<p>
    Машинное обучение бурно развивается, поэтому постоянно появляются новые
    не перечисленные здесь сферы применения.<br/>
</p>

<h3><a name="ref1.6">Краткая история</a></h3>

<p>
    Термин «машинное обучение» в 1959 году ввёл исследователь в области компьютерных игр
    Артур Самуэль в своей работе «Некоторые исследования в области Машинного Обучения
    с использованием игры в шашки» [1.4] и определил его как «процесс, в результате которого
    машина (компьютер) способна показывать поведение, которое в неё не было явно заложено
    (запрограммировано)». Игру в шашки, изобретенную Самуэлем в 1952 году, принято считать
    первой программой, способной самообучаться. Самуэль выбрал шашки, потому что правила игры
    относительно просты, но имеют развитую стратегию.<br/>
</p>

<p>
    Эффективность машинного обучения в решении задач была продемонстрирована достаточно давно:
    еще в 1936 году знаменитый английский статистик Рональд Фишер сумел научить компьютер
    определять вид ириса по ширине цветка и чашелистика.<br/>
</p>

<p>
    В тридцатые годы 20 века Карел Чапек изобрел термин «робот», в сороковые годы Айзек Азимов
    сформулировал законы робототехники, но первым, кто перевёл проблему «интеллектуальных машин»
    из научной фантастики в разряд прикладных проблем был математик Алан Тьюринг. В 1950 году
    в своей работе «Вычислительные машины и разум» [1.5] он рассмотрел вопрос
    «Могут ли машины думать?», но так как термины «машины» и «думать» не могут быть определены
    однозначно, Тьюринг предложил заменить вопрос на другой, тесно связанный с первым, но выраженный
    не такими двусмысленными понятиями: <i>может ли машина совершать действия, неотличимые от
    обдуманных действий</i>. С помощью такой постановки вопроса можно избежать сложных философских
    проблем по определению терминов «думать», «мышление» и сосредоточить внимание
    на решении практических задач.<br/>
</p>

<p>
    Заменив философский вопрос на прикладной, Тьюринг предложил для проверки возможностей компьютерной
    программы свой знаменитый <i>Тест Тьюринга</i>. Стандартная интерпретация этого теста звучит
    следующим образом: «Человек взаимодействует с одним компьютером и одним человеком.
    На основании ответов на вопросы он должен определить, с кем он разговаривает: с человеком
    или компьютерной программой. Задача компьютерной программы – ввести человека в заблуждение,
    заставив сделать неверный выбор». Однако Тьюринг говорит не об одурачивании людей,
    а о воспроизведении когнитивных способностей человека [1.6]. Хотя бы внешне.<br/>
</p>

<p>Тест Тьюринга имеет недостатки:</p>
<ul>
    <li>чрезмерный антропоморфизм (рисунок 1.5);</li>
    <li>непрактичность – самолёты не машут крыльями, как птицы, чтобы летать, а машины не обязаны
        имитировать поведение людей, чтобы решать прикладные задачи;</li>
    <li>возможность имитации «мышления» по неким механическим правилам, например, как в мысленном
        эксперименте «Китайская комната» Джона Сёрля (John Searle, 1980).</li>
</ul>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.5-Povedeniye-cheloveka-i-razumnoye-povedeniye.png"
         alt="Поведение человека и разумное поведение"
         title="Поведение человека и разумное поведение"
         height="220" /><br/>
    <div class="picture">Рис. 1.5 – Поведение человека и разумное поведение</div>
</div>

<p>
    Несмотря на обоснованную критику, тест Тьюринга задаёт правильное направление мысли, а именно:
    не важно, думает машина или нет, потому что нет однозначного определения слов «думать» или «интеллект»,
    главное, что машина <i>может</i> справляться с поставленными перед ней сложными задачами, например,
    имитировать поведение человека.<br/>
</p>

<p>
    Современный интерес к машинному обучению возрос после того, как искусственные нейронные сети
    вновь стали популярными. <i>Искусственная нейронная сеть</i> (ИНС) – это математическая модель,
    а также её программное или аппаратное воплощение, построенная по принципу организации и
    функционирования биологических нейронных сетей, т.е. сетей нервных клеток живого организма.
    Необязательно, чтобы строение ИНС и мозга совпадали. В ИНС воплощены идеи <i>коннекционизма</i>,
    т.е. моделирования мыслительных или поведенческих явлений в сетях
    из связанных между собой простых элементов.<br/>
</p>

<p>
    Первой попыткой построить ИНС по принципу функционирования мозга были нейронные сети
    Уоррена Мак-Каллока и Уолтера Питтса, описанные в статье 1943 года «Логическое исчисление идей,
    относящихся к нервной активности» [1.7, 1.8]. По примеру классических философов Греции они
    попытались математически смоделировать работу мозга. Это была яркая идея, учитывая то,
    что электрическая природа сигналов нейронов будет продемонстрирована только спустя семь лет
    в конце 1950-х годов. Математическая модель сети Мак-Каллока и Питтса из искусственных нейронов
    (рисунок 1.6) теоретически могла выполнять числовые или логические операции любой сложности.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.6-Skhema-iskusstvennogo-neyrona.png"
         alt="Схема искусственного нейрона"
         title="Схема искусственного нейрона"
         height="360" /><br/>
    <div class="picture">
        Рис. 1.6 – Схема искусственного нейрона:<br/>
        1) нейроны, выходные сигналы которых поступают на вход данному;<br/>
        2) ω<sub>i</sub> – веса входных сигналов; 3) сумматор входных сигналов;<br/>
        4) вычислитель передаточной (активационной) функции;<br/>
        5) нейроны, на входы которых подаётся выходной сигнал данного<br/>
    </div>
</div>

<p>
    На вход искусственного нейрона поступают импульсы от произвольного числа других нейронов сети.
    Связи, по которым выходные сигналы одних нейронов поступают на входы других, часто называют
    <i>синапсами</i> по аналогии со связями между биологическими нейронами.
    Каждая связь характеризуется своим весом. Связи с положительным весом называются возбуждающими,
    а с отрицательным – тормозящими. Нейрон имеет один выход, часто называемый <i>аксоном</i>
    по аналогии с биологическим прототипом. С единственного выхода нейрона сигнал может поступать
    на произвольное число входов других нейронов. Если на выходе нейрона есть ненулевой сигнал
    (положительный или отрицательный), то говорят, что нейрон активен или возбуждён.<br/>
</p>

<p>
    В сумматоре поступающие импульсы на вход нейрона умножаются на веса входов и слаживаются:<br/>
</p>

<table class="formula">
    <tr>
        <td class="formula"></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Formula1.1-Indutsirovannoye-lokalnoye-pole-neyrona.png"
                 alt="Индуцированное локальное поле нейрона или взвешенная сумма"
                 title="Индуцированное локальное поле нейрона или взвешенная сумма"
                 class="formula" /></td>
        <td class="formula">(1.1)</td>
    </tr>
</table>

<p class="formula">
    где <span class="formula">n</span> – количество входящих синапсов;
    <span class="formula">ω<sub>i</sub></span> – веса входов (положительные возбуждающие
    или отрицательные тормозящие); <span class="formula">x<sub>i</sub></span> – сигналы на входах;
    <span class="formula">C</span> – константа для формирования порога чувствительности нейрона,
    которая называется сдвиг (bias). Функция <span class="formula">x</span> называется индуцированным
    локальным полем нейрона или <i>взвешенной суммой</i>. Возможные значения сигналов на входах
    нейрона <span class="formula">x<sub>i</sub></span> считают заданными в интервале
    <span class="formula">[0,1]</span>. Сигналы на входах, в зависимости от архитектуры сети,
    могут быть либо дискретными (только 0 или только 1), либо аналоговыми
    (непрерывными в интервале от 0 до 1 включительно).<br/>
</p>

<p>
    Затем к индуцированному локальному полю нейрона <span class="formula">x</span>
    <span class="nowrap">(см. формулу 1.1)</span> применяется функция, называемая передаточной
    функцией <span class="formula">&fnof;(x)</span> или функцией активации, функцией срабатывания,
    которая определяет зависимость сигнала на выходе нейрона от взвешенной суммы сигналов на его
    входах. Использование различных передаточных функций позволяет вносить нелинейность в работу
    нейрона и в целом нейронной сети. Без этой нелинейности нейронная сеть вырождается в задачу
    линейной алгебры, т.е. в обычное перемножение матриц и векторов.<br/>
</p>

<p>
    Существует множество различных передаточных функций. Самой известной передаточной функцией
    является <i>функция Хевисайда</i> (рисунок 1.7), которая представляет собой перепад (ступеньку)
    и записывается формулой:<br/>
</p>

<table class="formula">
    <tr>
        <td class="formula"></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Formula1.2-Funktsiya-Khevisayda-ili-stupenka.png"
                 alt="Функция Хевисайда или «ступенька»"
                 title="Функция Хевисайда или «ступенька»"
                 class="formula" /></td>
        <td class="formula">(1.2)</td>
    </tr>
</table>

<p class="formula">
    где переменная <span class="formula">x</span> является индуцированным локальным полем
    (взвешенной суммой с порогом) и вычисляется по формуле (1.1).<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.7-Grafik-funktsii-Khevisayda-odnoy-iz-peredatochnykh-funktsiy.png"
         alt="График функции Хевисайда, одной из передаточных функций"
         title="График функции Хевисайда, одной из передаточных функций"
         height="180" /><br/>
    <div class="picture">Рис. 1.7 – График функции Хевисайда, одной из передаточных функций</div>
</div>

<p>
    Построения Мак-Каллока и Питтса были теоретическими, а в 1951 году Марвин Минский и Дин Эдмондс
    создают первую машину на нейронной сети: стохастический нейронный аналоговый калькулятор
    с подкреплением (Stochastic Neural Analog Reinforcement Calculator, SNARC).
    Машина состояла из 40 искусственных нейронов, соединённых в случайном порядке, была размером
    с рояль и с помощью обучения с подкреплением моделировала поведение крысы в лабиринте
    в поисках пищи. С помощью SNARC Марвин Минский проверял теорию Хебба о нейропластичности.<br/>
</p>

<p>
    В 1957 году Фрэнк Розенблатт изобретает <i>перцептрон</i> (от лат. perсeptio – восприятие) –
    математическую и компьютерную модель восприятия информации мозгом
    (кибернетическую модель мозга) [1.9]. Изучая нейронные сети типа перцептрона, Розенблатт хотел
    «понять фундаментальные законы организации, общие для всех систем обработки информации,
    включая как машины, так и человеческий разум». Перцептрон и, в частности, элементарный перцептрон
    состоит из трёх типов элементов и связей между ними (рисунок 1.8):<br>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.8-Pertseptron-s-tremya-vykhodami-i-elementarnyy-pertseptron.png"
         alt="Перцептрон с тремя выходами и элементарный перцептрон"
         title="Перцептрон с тремя выходами и элементарный перцептрон"
         height="340" /><br/>
    <div class="picture">
        Рис. 1.8 – 1) схема перцептрона с тремя выходами;<br/>
        2) элементарный перцептрон имеет только один выход<br/>
    </div>
</div>

<p>
    Сигналы на перцептрон поступают от S-элементов («S» от англ. «Sensor» – сенсор).
    S-элементы выдают дискретный сигнал: либо 1, либо 0. S-элементы не являются нейронами,
    потому что не обучаются, т.е. не меняют веса связей с нейронами. Внутри S-элементов есть датчик,
    сенсор или рецептор. От воздействия какого-либо из видов энергии (например, свет, звук,
    давление, тепло и т.п.) датчик внутри S-элемента вырабатывает сигнал. Если сигнал от датчика
    превышает некоторый порог, то на выходе S-элемента получается сигнал +1, иначе – 0 (нет сигнала).
    Поведение S-элемента описывается функцией Хевисайда (1.2) с некоторым порогом срабатывания
    <span class="formula">C</span> <span class="nowrap">(см. формулу 1.1)</span>.
</p>

<p>
    S-элементы соединяются синапсами, S–A связями, с A-элементами. Веса S–A связей могут иметь три
    дискретных значения: (–1) (тормозящий синапс), (+1) (возбуждающий синапс) и 0 (отсутствие синапса,
    когда нет физической связи между сенсором S и нейроном A). S–A связи выбираются случайным,
    но фиксированным образом, т.е. не меняются во время обучения и работы сети.<br/>
</p>

<p>
    A-элементы («A» от англ. «Associative» – ассоциативный) называются ассоциативными, потому что
    каждому такому элементу, как правило, соответствует целый набор (ассоциация) S-элементов.
    A-элементы являются искусственными нейронами <span class="nowrap">(см. рисунок 1.6)</span>.
    Передаточной функцией (функцией активации) нейрона для A-элементов является функция
    Хевисайда (1.2). Таким образом, A-элемент активизируется, как только взвешенная сумма
    сигналов от S-элементов на его входе превысит некоторую пороговую величину
    <span class="formula">C</span> <span class="nowrap">(см. формулу 1.1)</span>,
    и индуцированное локальное поле нейрона станет больше либо равным нулю:
    <span class="formula">x ≥ 0</span>. В соответствии с функцией Хевисайда, выходной сигнал
    ассоциативных нейронов является дискретным: либо 0 (нет сигнала), либо 1 (есть сигнал).<br/>
</p>

<p>
    A-элементы соединяются синапсами (A–R связями) с R-элементами. Сигнал от
    <span class="formula">i</span>-того ассоциативного элемента передаётся в
    <span class="formula">j</span>-тый реагирующий элемент с коэффициентом
    <span class="formula">W<sub>i,j</sub></span>. Этот коэффициент называется весом A–R связи.
    Веса A–R связей <span class="formula">W<sub>i,j</sub></span> могут быть любыми
    (являются вещественными числами). A–R связи выбираются случайным, но фиксированным образом,
    т.е. не меняются во время обучения и работы сети. Обучение перцептрона состоит в изменении
    весовых коэффициентов <span class="formula">W<sub>i,j</sub></span>.<br/>
</p>

<p>
    R-элементы («R» от англ. «Reacting» – реагирующий) называются реагирующими,
    потому что эти нейроны выдают результат, реагируют на входные импульсы от сенсоров.
    R-элементы являются искусственными нейронами (см. рисунок 1.6). Реагирующий элемент выдаёт
    выходной дискретный сигнал: (+1), если сумма значений входных сигналов, помноженных на веса,
    является строго положительной; (–1), если сумма значений входных сигналов, помноженных на веса,
    является строго отрицательной. Если сумма значений входных сигналов, помноженных на веса,
    равна нулю, то выход можно считать либо равным нулю, либо неопределённым.
    Таким образом, передаточной функцией (функцией активации) нейрона для R-элементов является
    <i>сигнум функция</i> (сигнум, от лат. «signum» – знак):<br/>
</p>

<table class="formula">
    <tr>
        <td class="formula"></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Formula1.3-Signum-funktsiya-sign.png"
                 alt="Cигнум функция, sign(x)"
                 title="Cигнум функция, sign(x)"
                 class="formula" /></td>
        <td class="formula">(1.3)</td>
    </tr>
</table>

<p class="formula">
    где <span class="formula">x</span> является индуцированным локальным полем нейрона и вычисляется
    по формуле (1.1). График сигнум функции изображён на рисунке 1.9.
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.9-Grafik-signum-funktsii-sign(x).png"
         alt="График сигнум функции sign(x)"
         title="График сигнум функции sign(x)"
         height="200" /><br/>
    <div class="picture">Рис. 1.9 – График сигнум функции <span class="formula">sign(x)</span></div>
</div>

<p>Согласно современной терминологии классический перцептрон является искусственной нейронной сетью:</p>
<ul>
    <li>с одним скрытым слоем, трёхслойный по классификации Розенблатта и двухслойный по современной
        системе обозначений с той особенностью, что первый слой не обучаемый;</li>
    <li>с пороговой функцией активации Хевисайда (1.2) для ассоциативных нейронов
        и сигнум функцией активации (1.3) для реагирующих нейронов;</li>
    <li>с прямым распространением сигнала (без обратной связи).</li>
</ul>

<p>
    Классический метод обучения перцептрона – это обучение с коррекцией ошибки, специальный
    итерационный метод обучения проб и ошибок, который напоминает процесс обучения человека.
    Представляет собой такой метод обучения с учителем, при котором вес
    <span class="formula">W<sub>i,j</sub></span> связи A–R не изменяется до тех пор, пока текущая
    реакция перцептрона остаётся правильной. При появлении неправильной реакции вес изменяется на
    единицу, а знак изменения (+1 или –1) определяется противоположным от знака ошибки. Например,
    мы хотим обучить элементарный перцептрон <span class="nowrap">(см. рисунок 1.8.2)</span>
    разделять два класса объектов, круги и квадраты, так, чтобы при предъявлении объектов первого
    класса (круги) выход перцептрона был положителен (+1), а при предъявлении объектов второго
    класса (квадраты) – отрицательным (−1). Для этого выполним следующий алгоритм:<br/>
</p>

<ol>
    <li>Случайным образом выбираем пороги <span class="formula">C</span>
        <span class="nowrap">(см. формулу 1.1)</span> для A-элементов. Случайным образом
        устанавливаем связи S–A. Далее пороги и связи не изменяются. Все A-элементы элементарного
        перцептрона соединены одной A–R связью с единственным выходным R-элемента
        <span class="nowrap">(см. рисунок 1.8.2)</span>.</li>
    <li>Начальные коэффициенты <span class="formula">W<sub>i</sub></span> полагаем равными нулю.</li>
    <li>Предъявляем обучающую выборку: круги и квадраты с указанием класса, к которым они принадлежат.
        <ol>
            <li>Если предъявили круг и выход перцептрона положительный – ничего не делаем.</li>
            <li>Если предъявили квадрат и выход перцептрона отрицательный – ничего не делаем.</li>
            <li>Если предъявили круг и выход перцептрона отрицательный – к весу
                <span class="formula">W<sub>i</sub></span> каждого активного А-элемента
                прибавляется единица. Активный элемент тот, который выдаёт единицу на выходе.
                Если элемент не активный (ноль на выходе), то единица к весу этого элемента
                не прибавляется.</li>
            <li>Если предъявили квадрат и выход перцептрона положительный – от веса
                <span class="formula">W<sub>i</sub></span> каждого активного A-элемента
                отнимается единица.</li>
        </ol>
    </li>
    <li>Шаг 3 выполним для всей обучающей выборки. В результате обучения сформируются значения
        весов A–R связей <span class="formula">W<sub>i</sub></span>.</li>
</ol>

<p>
    В книге 1962 года «Принципы нейродинамики: Перцептроны и теория механизмов мозга» [1.10]
    Розенблатт сформулировал и доказал теорему о сходимости перцептрона: элементарный перцептрон,
    обучаемый по методу коррекции ошибки (с квантованием или без него), независимо от начального
    состояния весовых коэффициентов и порядка показа образцов из обучающей выборки всегда научится
    различать два класса объектов за конечное число шагов, если только существует такая классификация.
    Также в книге рассматриваются:<br/>
</p>

<ul>
    <li>многослойные перцептроны с дополнительными слоями A-элементов;</li>
    <li>перцептроны с перекрёстными связями, т.е. со связями между элементами одного слоя;</li>
    <li>перцептроны с обратными связями, которые согласно современной классификации
        относится к рекуррентным нейронным сетям (RNN);</li>
    <li>обучение без учителя или альфа-система подкрепления – это система подкрепления,
        при которой веса всех активных связей <span class="formula">W<sub>i,j</sub></span>,
        которые ведут к элементу <span class="formula">u<sub>j</sub></span>, изменяются
        на одинаковую величину, а веса неактивных связей за это время не изменяются.</li>
</ul>

<p>
    Сначала перцептрон был реализован, как компьютерная программа, а впоследствии в 1960 году,
    как электронное устройство – нейрокомпьютер Марк-1. Классификатор визуальных образов Марк-1
    имел входной (сенсорный) слой из 400 светочувствительных S-элементов в сетке 20х20 (400 пикселей),
    моделирующий небольшую сетчатку, как светочувствительные клетки сетчатки глаза или фоторезисторы
    матрицы камеры. Далее был слой ассоциации из 512 A-элементов, сделанных с применением шаговых
    двигателей. Каждый из A-элементов мог принимать несколько возбуждающих и тормозящих входов от
    S-элементов. После слоя ассоциации располагался выходной (ответный) слой из восьми R-элементов.
    Сенсорный слой случайным образом соединялся с ассоциативным слоем с помощью S–A связей на
    специальной приборной доске, но после установки соединения все S–A связи оставались неизменными
    до конца эксперимента. A–R связи между ассоциативным и выходным слоями имели переменные веса
    (потенциометры с двигателем). Переменные веса корректировались с помощью метода коррекции ошибки.
    Нейрокомпьютер Марк-1 состоял из шести стоек электронного оборудования и занимал примерно
    <span class="nowrap">3,4 м2</span> площади. Марк-1 был способен распознавать некоторые буквы
    английского алфавита, написанные на карточках, которые подносили к его «глазам»
    из 400 фотосенсоров.<br/>
</p>

<p>
    В 1969 году вышла книга Марвина Минского (того самого, который сделал первый нейрокомпьютер SNARC)
    и Сеймура Паперта «Перцептроны» [1.11], в которой были математически доказаны ограничения перцептронов.
    Было показано, что перцептроны принципиально не в состоянии выполнять многие из тех функций,
    которые хотели от них получить. Минский показал преимущество последовательных вычислений перед
    параллельными в определённых классах задач. В то время была слабо развита теория о параллельных
    вычислениях, а перцептрон полностью соответствовал принципам параллельных вычислений.
    Некоторые ограничения перцептрона показаны на рисунке 1.10.<br/>
</p>

<div class="image">
    <img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Ris1.10-Ogranicheniya-pertseptrona.png"
         alt="Ограничения перцептрона"
         title="Ограничения перцептрона"
         height="200" /><br/>
    <div class="picture">
        Рис. 1.10 – Ограничения перцептрона:<br/>
        1) Это одна и та же буква? 2) Это один и тот же текст?<br/>
        3) Из какого количества частей состоит фигура?<br/>
        4) Внутри какого объекта нет другой фигуры?<br/>
        5) Какая фигура внутри объектов повторяется два раза?<br/>
    </div>
</div>

<p>Основными недостатками классического перцептрона являются:</p>

<ul>
    <li>трудности с распознаванием объекта, над которым провели операции переноса, поворота,
        растяжения-сжатия <span class="nowrap">(рисунки 1.10.1 и 1.10.2)</span>;</li>
    <li>неспособность решать задачи на определение «связности» фигур
        <span class="nowrap">(рисунки 1.10.3, 1.10.4 и 1.10.5)</span>.</li>
</ul>

<p>
    В начале 60-х годов многими математиками в рамках теории управления были заложены основы метода
    <i>обратного распространения ошибки</i> (backpropagation), который необходим для глубокого обучения
    (Deep Learning) [1.12]. Однако метод обратного распространения ошибки не применялся
    непосредственно к нейронным сетям до 80-х годов.<br/>
</p>

<p>
    В процессе своего развития машинное обучение пережило две «зимы искусственного интеллекта».
    Зимой искусственного интеллекта называется период сниженного общественного интереса и
    существенного уменьшения финансирования исследований в этой области со стороны бизнеса и
    государственных организаций. Различают две зимы 1974–1980 и 1987–1993 годов, а также несколько
    меньших периодов, связанных с провалами крупных проектов в этой области. Несмотря на
    низкое финансирование, исследования в области машинного обучения продолжались.
    Часто под другими названиями.<br/>
</p>

<h3><a name="ref1.7">Модели машинного обучения</a></h3>

<p>
    В машинном обучении существует огромное количество различных моделей,
    самыми популярными из которых являются:<br/>
</p>

<ul>
    <li>метод опорных векторов (support vector machine, SVM);</li>
    <li>метод k-ближайших соседей (k-nearest neighbors, k-NN);</li>
    <li>дерево принятия решений (decision tree) и случайный лес (random forest);</li>
    <li>гауссовский процесс (Gaussian process);</li>
    <li>байесовская теория классификации;</li>
    <li>эволюционные алгоритмы, которые моделируют процессы естественного отбора;</li>
    <li>алгоритмы усиления (бустинга): AdaBoost, BrownBoost, CoBoost и т.д.;</li>
    <li>ансамблевое обучение (ensemble learning);</li>
    <li>марковские процессы;</li>
    <li>мешок слов;</li>
    <li>метод главных компонент (principal component analysis, PCA);</li>
    <li>искусственные нейронные сети;</li>
    <li>линейная и логистическая регрессии;</li>
    <li>метод k-средних (k-means);</li>
    <li>и др.</li>
</ul>

<h3><a name="ref1.8">Список литературы</a></h3>

<p>
    1.1. Box G.E.P., Hunter W.G., Hunter J.S., ″Statistics for Experimenters: Design, Innovation,
    and Discovery,″ John Wiley & Sons, Hoboken, 2 ed., 2005, p. 664. ISBN: 978-0471718130.<br/>
</p>

<p>
    1.2. O. Duchenne, J. Y. Audibert, R. Keriven, J. Ponce and F. Segonne, ″Segmentation by
    transduction,″ 2008 IEEE Conference on Computer Vision and Pattern Recognition, Anchorage,
    AK, 2008, pp. 1-8, doi: 10.1109/CVPR.2008.4587419<br/>
</p>

<p>
    1.3. Дюк В.А., Флегонтов А.В., Фомина И.К. Применение технологий интеллектуального анализа данных
    в естественнонаучных, технических и гуманитарных областях // Известия Российского государственного
    педагогического университета им. А.И. Герцена. 2011. No 138. С. 77-84.<br/>
</p>

<p>
    1.4. Samuel A.L., ″Some Studies in Machine Learning Using the Game of Checkers,″ in IBM Journal
    of Research and Development, Vol. 3, No. 3, July 1959, pp. 210-229, doi: 10.1147/rd.33.0210.<br/>
</p>

<p>
    1.5. Turing A.M., ″Computing machinery and intelligence,″ Oxford University Press on behalf
    of the Mind Association, Mind, New Series, Vol. 59, No. 236, Oct., 1950, pp. 433–460.<br/>
</p>

<p>
    1.6. Harnad S., ″The Turing Test Is Not A Trick: Turing Indistinguishability Is A Scientific
    Criterion,″ SIGART Bulletin, No. 3(4), October, 1992, pp. 9–10.<br/>
</p>

<p>
    1.7. McCalloch W.S., Pitts W., ″A Logical Calculus of Ideas Immanent in Nervous Activity,″
    Bulletin of Mathematical Biophysics, Vol. 5, 1943, pp. 115–133, doi: 10.1007/BF02478259<br/>
</p>

<p>
    1.8. Мак-Каллок У.С., Питтс В. Логическое исчисление идей, относящихся к нервной активности //
    В сб. «Автоматы» под ред. К.Э. Шеннона и Дж. Маккарти. – М.: Изд-во иностр. лит.,
    1956. – С. 363–384. (Перевод английской статьи 1943 г.)<br/>
</p>

<p>
    1.9. Rosenblatt F., ″The perceptron: A probabilistic model for information storage and
    organization in the brain,″ Psychological Review, Vol. 65, No. 6, 1958,
    pp. 386–408, doi: 10.1037/h0042519<br/>
</p>

<p>
    1.10. Rosenblatt F., ″Principles of neurodynamics: Perceptions and the theory of brain mechanism,″
    Spartan Books, Washington, DC, 1962, p. 616.<br/>
</p>

<p>
    1.11. Marvin L. Minsky, Seymour A. Papert, ″Perceptrons: expanded edition,″ MIT Press Cambridge,
    MA, USA, 1988, p. 292. ISBN: 0-262-63111-3.<br/>
</p>

<p>
    1.12. Schmidhuber J., ″Deep learning in neural networks: An overview,″ Neural Networks,
    Vol. 61, 2015, pp. 85–117, doi: 10.1016/j.neunet.2014.09.003<br/>
</p>

<h2><a name="ref2">Глава 2. Введение в искусственные нейронные сети</a></h2>

<div class="citation">
    «Искусственный интеллект – это всё то, что ещё не сделано», –<br/>
    Дуглас Хофштадтер, физик и информатик<br/>
</div>

<h3><a name="ref2.1">Принципы работы искусственных нейронных сетей</a></h3>

<h4><a name="ref2.1.1">Обзор основных архитектур ИНС</a></h4>

<p>
    Одной из моделей машинного обучения являются <i>искусственные нейронные сети</i> (ИНС).
    В настоящее время происходит возрождение ИНС под новым брендом «глубокое обучение»
    (Deep Learning). ИНС являются иерархическими классификаторами, которые способны самостоятельно
    выделять признаки в исходном сигнале. Общим показателем ИНС является количество скрытых слоёв.
    Некоторые современные сети имеют сотни и даже тысячи скрытых слоёв. Выделяют большое множество
    (зоопарк) архитектур ИНС. Перечислим самые популярные из них.<br/>
</p>

<p>
    <i>Сети без обратных связей</i> или сети прямого распространения сигнала, в которых сигнал
    переходит от выходов нейронов <span class="formula">i</span>-того слоя ко входам нейронов
    <span class="formula">(i+1)</span>-го слоя и не возвращается на предыдущие слои:<br/>
</p>

<ul>
    <li>перцептроны (однослойные, многослойные с перекрёстными связями и т.д.), кроме перцептронов с обратными связями;</li>
    <li>байесовская нейронная сеть;</li>
    <li>экстремальная обучающаяся машина (extreme learning machine);</li>
    <li>фактически, любая ИНС, которая является направленным ациклическим (без циклов) графом.</li>
</ul>

<p>
    <i>Свёрточные</i> нейронные сети (Convolutional Neural Networks, CNN, ConvNets),
    отличительной особенностью которых является операция свёртки (конволюция):<br/>
</p>

<ul>
    <li>AlexNet [2.1];</li>
    <li>LeNet-5 [2.2];</li>
    <li>свёрточные сети с выделением области (Region Based CNNs, R-CNN) [2.3];</li>
    <li>развёртывающие нейронные сети (deconvolutional networks, DN, DeConvNet)
        или обратные графические сети, свёрточные сети наоборот [2.4].</li>
</ul>

<p>
    <i>Генеративные состязательные сети</i> (Generative adversarial networks, GAN) [2.5],
    которые состоят из двух конкурирующих ИНС: генеративной модели, генерирующей образцы,
    и дискриминативной модели, пытающейся отличить правильные («подлинные») образцы от неправильных.
    GAN достаточно сложно обучить, потому что задачей является не просто обучение двух сетей,
    но и соблюдение баланса, равновесия между ними. Если одна из сетей (генератор или дискриминатор)
    станет намного лучше другой, то GAN не будет сходиться (обучаться).<br/>
</p>

<p>
    <i>Рекуррентные</i> нейронные сети (Recurrent Neural Networks, RNN) [2.6, 2.7, 2.8]
    или сети с памятью. Содержат нейроны, которые в процессе работы могут сохранять информацию
    о своих предыдущих состояниях, такие нейроны получают информацию не только от предыдущего слоя,
    но и от самих себя в результате предыдущего прохода. Рекуррентные сети являются нейросетевым
    воплощением цепей Маркова. Различают множество архитектур рекуррентных ИНС:<br/>
</p>

<ul>
    <li>сеть с долговременной и кратковременной памятью (Long Short Term Memory, LSTM);</li>
    <li>полностью рекуррентная сеть;</li>
    <li>рекурсивная сеть;</li>
    <li>нейронная сеть Хопфилда, один из видов полносвязных ИНС;</li>
    <li>машина Больцмана и ограниченная машина Больцмана;</li>
    <li>нейронная сеть Хэмминга;</li>
    <li>двунаправленная ассоциативная память (BAM) или нейронная сеть Коско;</li>
    <li>двунаправленные рекуррентные ИНС (bidirectional recurrent neural networks);</li>
    <li>сети Элмана и Джордана;</li>
    <li>эхо-сети и импульсные (спайковые) нейронные сети;</li>
    <li>машины неустойчивых состояний (liquid state machines, LSM);</li>
    <li>нейронный компрессор истории;</li>
    <li>рекуррентные сети второго порядка;</li>
    <li>управляемые рекуррентные нейроны (Gated Recurrent Units, GRU);</li>
    <li>нейронные машины Тьюринга (Neural Turing machines, NTM) и т.д.</li>
</ul>

<p>
    <i>Автокодировщики</i>, задачей которых является получение на выходном слое отклика,
    наиболее близкого к входному. По этой причине выходной слой автокодировщика должен содержать
    столько же нейронов, сколько и входной слой. Сеть напоминает по форме песочные часы,
    так как скрытые слои автокодировщиков меньше, чем входной и выходной слои.
    Различают следующие автокодировщики:<br/>
</p>

<ul>
    <li>ванильный автокодировщик (Vanilla autoencoder);</li>
    <li>многослойный автокодировщик;</li>
    <li>свёрточный автокодировщик;</li>
    <li>упорядоченный автокодировщик (regularized autoencoder);</li>
    <li>разреженный автокодировщик;</li>
    <li>шумоподавляющий (помехоустойчивый) автокодировщик (denoising autoencoder, DAE).</li>
</ul>

<p>
    <i>Глубокие</i> нейронные сети, которые отличаются от просто нейронных сетей
    наличием большого количества скрытых слоёв:<br/>
</p>

<ul>
    <li>глубокие сети доверия (Deep Belief Networks, DBN),
        которые являются первыми глубокими сетями;</li>
    <li>глубокая остаточная нейронная сеть (Residual neural network, ResNet) [2.9],
        которая является попыткой смоделировать пирамидальные нейроны в коре больших полушарий;</li>
    <li>глубокая машина Больцмана (Deep Boltzmann Machine, DBM);</li>
    <li>размещённые друг над другом автокодировщики (Stacked Auto-Encoders);</li>
    <li>глубокие свёрточные нейронные сети (Deep Convolutional Neural Networks, DCNN),
        глубокие свёрточные обратные глубинные сети (Deep Convolutional Inverse Graphics Networks,
        DCIGN) [2.10], VGG Net [2.11] и т.д.</li>
</ul>

<p>
    Нейронные сети <i>Кохонена</i>, у которых основным элементом является слой Кохонена.
    В этом слое выходные сигналы обрабатываются по правилу «победитель получает всё»,
    т.е. наибольший сигнал превращается в единичный, а остальные обращаются в ноль:<br/>
</p>

<ul>
    <li>сети векторного квантования (learning vector quantization);</li>
    <li>самоорганизующиеся карты Кохонена;</li>
    <li>упругие карты.</li>
</ul>

<p>
    Сети <i>радиально-базисных функций</i> (radial basis function networks),
    которые использует радиальные базисные функции в качестве функций активации.<br/>
</p>

<p>
    Смешанные нейронные сети, которые совмещают в себе различные архитектуры
    для большей эффективности:<br/>
</p>

<ul>
    <li>GoogLeNet;</li>
    <li>AlphaGo и т.д.</li>
</ul>

<p>
    Этот список не является исчерпывающим. Постоянно появляются новые архитектуры.
    Более того, вышеизложенное разделение ИНС на архитектуры является условным,
    так как нет чётких границ. Например, свёрточная ИНС одновременно является сетью
    без обратных связей, она же глубокая нейронная сеть, а также она может являться
    автокодировщиком или частью более сложной архитектуры. К сожалению, в этой главе
    нет возможности подробно описать архитектуру каждой сети. Однако все ИНС используют
    общие принципы работы и имеют схожие проблемы обучения, кратко рассмотренные ниже.<br/>
</p>

<p>
    Существует множество программных библиотек для машинного обучения и обучения ИНС: TensorFlow,
    Theano, Keras, Torch, Caffe, MXNet, Matlab Neural Networks Toolbox, Wolfram Mathematica и др.<br/>
</p>

<h3><a name="ref2.1.2">Функции активации нейрона</a></h3>

<p>
    В предыдущей главе были рассмотрены две ступенчатые функции активации перцептрона:
    функция Хевисайда (1.2) и сигнум-функция (1.3). В современных ИНС широко применяется метод
    обратного распространения ошибки (backpropagation), в котором используется производная
    от функции активации. Но ступенчатые функции не дифференцируемы, т.е. не имеют производной
    на ступеньке. Поэтому при использовании метода обратного распространения ошибки применяются
    другие функции активации. В таблице 2.1 показаны несколько самых широко применяемых
    в ИНС функций активации.<br/>
</p>

<table>
    <caption>Таблица 2.1 – Функции активации нейрона в ИНС</caption>
    <tr>
        <th>№</th>
        <th>Название</th>
        <th>Формула</th>
        <th>Изображение</th>
    </tr>
    <tr>
        <td>1</td>
        <td>Rectified linear unit (ReLU)</td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Rectified-linear-unit-ReLU.png"
                 alt="Rectified linear unit (ReLU)"
                 title="Rectified linear unit (ReLU)" /></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Funktsiya-aktivatsii-neyrona-Rectified-linear-unit-ReLU.png"
                 alt="Rectified linear unit (ReLU)"
                 title="Rectified linear unit (ReLU)"
                 height="120" /></td>
    </tr>
    <tr>
        <td>2</td>
        <td>Параметрический rectified linear unit (PReLU)</td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Parametric-rectified-linear-unit-PReLU.png"
                 alt="Параметрический rectified linear unit (PReLU)"
                 title="Параметрический rectified linear unit (PReLU)" /></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Funktsiya-aktivatsii-neyrona-Parametric-rectified-linear-unit-PReLU.png"
                 alt="Параметрический rectified linear unit (PReLU)"
                 title="Параметрический rectified linear unit (PReLU)"
                 height="120" /></td>
    </tr>
    <tr>
        <td>3</td>
        <td>Логистическая функция или сигмоида</td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Logisticheskaya-funktsiya-Sigmoid.png"
                 alt="Логистическая функция или сигмоида"
                 title="Логистическая функция или сигмоида" /></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Funktsiya-aktivatsii-neyrona-Logisticheskaya-funktsiya-Sigmoid.png"
                 alt="Логистическая функция или сигмоида"
                 title="Логистическая функция или сигмоида"
                 height="120" /></td>
    </tr>
    <tr>
        <td>4</td>
        <td>Гиперболический тангенс (TanH)</td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Giperbolicheskiy-tangens-TanH.png"
                 alt="Гиперболический тангенс (TanH)"
                 title="Гиперболический тангенс (TanH)" /></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Funktsiya-aktivatsii-neyrona-Giperbolicheskiy-tangens-TanH.png"
                 alt="Гиперболический тангенс (TanH)"
                 title="Гиперболический тангенс (TanH)"
                 height="120" /></td>
    </tr>
    <tr>
        <td>5</td>
        <td>Арктангенс (ArcTan)</td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Arktangens-ArcTan.png"
                 alt="Арктангенс (ArcTan)"
                 title="Арктангенс (ArcTan)" /></td>
        <td><img src="https://raw.githubusercontent.com/foobar167/articles/master/Machine_Learning/Brochure/data/Tab2.1-Funktsiya-aktivatsii-neyrona-Arktangens-ArcTan.png"
                 alt="Арктангенс (ArcTan)"
                 title="Арктангенс (ArcTan)"
                 height="120" /></td>
    </tr>
</table>

<p>
    Здесь аргумент активационной функции <span class="formula">x</span> – это взвешенная сумма (1.1)
    или индуцированное локальное поле; <span class="formula">α</span> во второй строке таблицы 2.1 –
    это малый коэффициент, обычно равный <span class="formula">α = 0,01</span>. Малый коэффициент
    <span class="formula">α</span> нужен, чтобы производная функции ReLU не была равна нулю при
    <span class="formula">x < 0</span>. Однако наличие малого коэффициента <span class="formula">α</span>
    некритично, как может показаться, так как вероятность того, что активационные функции всех
    нейронов ИНС станут равными нулю крайне мала. Например, в одномерном случае невозможно
    преодолеть гору, в двумерном случае гору можно обойти слева или справа, а в многомерном
    <span class="formula">N</span>-мерном пространстве существует множество путей обхода препятствий,
    и чем больше измерений, тем меньше вероятность попасть в локальный минимум.<br/>
</p>

</body>
</html>
